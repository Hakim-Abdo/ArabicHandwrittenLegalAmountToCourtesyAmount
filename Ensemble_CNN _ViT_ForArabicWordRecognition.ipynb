{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S165N69WgJli"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "# import cv2\n",
    "from random import shuffle\n",
    "from tensorflow.keras import layers\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from collections import Counter\n",
    "from tensorflow import keras\n",
    "\n",
    "#import util_layers\n",
    "#import swin_layers\n",
    "#import transformer_layers\n",
    "from tensorflow.keras.layers import Input, Dense, GlobalAveragePooling1D, Layer, Dropout, Flatten\n",
    "import warnings\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow_addons as tfa\n",
    "from vit_keras import vit\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eYCaA87in86"
   },
   "source": [
    "# Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GfpqlNdwOt12",
    "outputId": "0c5f21dd-1bc3-4637-9c6e-7c322d537473"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "batchsize=16\n",
    "image_size=224\n",
    "\n",
    "visible = tf.keras.layers.Input(shape=(image_size, image_size, 3))\n",
    "train_dir = 'C:/my data/datasetV3/train'\n",
    "validation_dir = 'C:/my data/datasetV3/validation'\n",
    "test_dir = 'C:/my data/datasetV3/test'\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   #shear_range = 0.2,\n",
    "                                   #zoom_range = 0.2,\n",
    "                                   #validation_split=0.2,\n",
    "                                   #horizontal_flip = True\n",
    "                                   )\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_dir,\n",
    "                                                 target_size = (image_size, image_size),\n",
    "                                                 batch_size = batchsize,\n",
    "                                                 #subset=\"training\",\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "validation_set = train_datagen.flow_from_directory(validation_dir,\n",
    "                                                 target_size = (image_size, image_size),\n",
    "                                                 batch_size = batchsize,\n",
    "                                                #subset=\"validation\",\n",
    "                                                shuffle = False,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(test_dir,\n",
    "                                       batch_size = batchsize,\n",
    "                                       shuffle = False,\n",
    "\n",
    "                                       target_size = (image_size, image_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGoKMS8JymxH"
   },
   "source": [
    "# main fuctons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-UfBJwGFgj7S"
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_training_curves(training_accuracy, validation_accuracy, title, subplot):\n",
    "    if subplot % 10 == 1:\n",
    "        plt.subplots(figsize=(10, 10))\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.plot(training_accuracy)\n",
    "    ax.plot(validation_accuracy)\n",
    "    ax.set_title('Model ' + title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train_Accuracy', 'Val_Accuracy'])\n",
    "\n",
    "\n",
    "def display_training_curves2(training_loss, validation_loss, title, subplot):\n",
    "    if subplot % 10 == 1:\n",
    "        plt.subplots(figsize=(10, 10))\n",
    "        plt.tight_layout()\n",
    "    ax = plt.subplot(subplot)\n",
    "    ax.plot(training_loss)\n",
    "    ax.plot(validation_loss)\n",
    "    ax.set_title('Model ' + title)\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(['Train_Loss', 'Val_Loss'])\n",
    "\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, classifier_layer_names):\n",
    "    last_conv_layer = model.get_layer(last_conv_layer_name)\n",
    "    last_conv_layer_model = keras.Model(model.inputs, last_conv_layer.output)\n",
    "\n",
    "    # map the activations of the last conv layer to the final class predictions\n",
    "    classifier_input = keras.Input(shape=last_conv_layer.output.shape[1:])\n",
    "    x = classifier_input\n",
    "    for layer_name in classifier_layer_names:\n",
    "        x = model.get_layer(layer_name)(x)\n",
    "    classifier_model = keras.Model(classifier_input, x)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Compute activations of the last conv layer and make the tape watch it\n",
    "        last_conv_layer_output = last_conv_layer_model(img_array)\n",
    "        tape.watch(last_conv_layer_output)\n",
    "        preds = classifier_model(last_conv_layer_output)\n",
    "        top_pred_index = tf.argmax(preds[0])\n",
    "        top_class_channel = preds[:, top_pred_index]\n",
    "\n",
    "    grads = tape.gradient(top_class_channel, last_conv_layer_output)\n",
    "\n",
    "    # This is a vector where each entry is the mean intensity of the gradient over a specific feature map channel\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    last_conv_layer_output = last_conv_layer_output.numpy()[0]\n",
    "    pooled_grads = pooled_grads.numpy()\n",
    "    for i in range(pooled_grads.shape[-1]):\n",
    "        last_conv_layer_output[:, :, i] *= pooled_grads[i]\n",
    "\n",
    "    heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap, top_pred_index.numpy()\n",
    "\n",
    "\n",
    "def superimposed_img(image, heatmap):\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    jet = cm.get_cmap(\"jet\")\n",
    "    jet_colors = jet(np.arange(256))[:, :3]\n",
    "    jet_heatmap = jet_colors[heatmap]\n",
    "\n",
    "    # We create an image with RGB colorized heatmap\n",
    "    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)\n",
    "    jet_heatmap = jet_heatmap.resize((image_size, image_size))\n",
    "    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)\n",
    "\n",
    "    # Superimpose the heatmap on original image\n",
    "    superimposed_img = jet_heatmap * 0.4 + image\n",
    "    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)\n",
    "    return superimposed_img\n",
    "\n",
    "\n",
    "# label smoothing\n",
    "def categorical_smooth_loss(y_true, y_pred, label_smoothing=0.1):\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, label_smoothing=label_smoothing)\n",
    "    return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TI1ZeAe9-NpW"
   },
   "source": [
    "# build the hybrid model in parallel mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 688
    },
    "id": "NvGx7mS9hNN2",
    "outputId": "aac98103-b85d-4d86-cbb5-3a7acb59a002"
   },
   "outputs": [],
   "source": [
    "path='models_ouput/hybrid)ensemb(InceptionResNetV2_Xception)(parallel1)With_ViT'\n",
    "import tensorflow_addons as tfa\n",
    "image_size=224\n",
    "#pretrained_E = tf.keras.applications.EfficientNetV2B0(input_shape=(image_size, image_size, 3), weights='imagenet', include_top=False)\n",
    "#pretrained_VGG = tf.keras.applications.VGG16(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "#                                            include_top=False)\n",
    "# pretrained_googleNet = tf.keras.applications.InceptionV3(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "#                                                          include_top=False)\n",
    "pretrained_IRV2 = tf.keras.applications.InceptionResNetV2(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "                                                         include_top=False)\n",
    "pretrained_Xception = tf.keras.applications.Xception(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "                                                     include_top=False)\n",
    "\n",
    "\n",
    "for layer in pretrained_IRV2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pretrained_Xception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "\n",
    "x4 = pretrained_IRV2(visible)\n",
    "x4 = tf.keras.layers.ZeroPadding2D(padding=((0, 2), (0, 2)))(x4)\n",
    "x4 = tf.keras.layers.AveragePooling2D()(x4)\n",
    "x4 = tf.keras.layers.Flatten()(x4)\n",
    "x4 = tf.keras.layers.Dense(32, activation=\"relu\")(x4)\n",
    "x4 = tf.keras.layers.Dropout(0.5)(x4)\n",
    "\n",
    "x5 = pretrained_Xception(visible)\n",
    "x5 = tf.keras.layers.AveragePooling2D()(x5)\n",
    "x5 = tf.keras.layers.Flatten()(x5)\n",
    "x5 = tf.keras.layers.Dense(32, activation=\"relu\")(x5)\n",
    "x5 = tf.keras.layers.Dropout(0.5)(x5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vit_model = vit.vit_b32(\n",
    "        image_size = image_size,\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False)\n",
    "\n",
    "\n",
    "\n",
    "vit_x=vit_model(visible)\n",
    "vit_x=tf.keras.layers.Flatten()(vit_x)\n",
    "vit_x=tf.keras.layers.BatchNormalization()(vit_x)\n",
    "vit_x=tf.keras.layers.Dense(32, activation = tfa.activations.gelu)(vit_x)\n",
    "\n",
    "merge = tf.keras.layers.concatenate([x4, x5, vit_x])\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(merge)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "OUT = tf.keras.layers.Dense(33, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=visible, outputs=OUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cAiSKfiFC-t"
   },
   "source": [
    "# build the hybrid model in serial mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zRWDsnscFIFf"
   },
   "outputs": [],
   "source": [
    "path='models_ouput/hybrid)ensemb(InceptionResNetV2_Xception)(serial)With_ViT'\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "\n",
    "pretrained_IRV2 = tf.keras.applications.InceptionResNetV2(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "                                                         include_top=False)\n",
    "pretrained_Xception = tf.keras.applications.Xception(input_shape=(image_size, image_size, 3), weights='imagenet',\n",
    "\n",
    "\n",
    "for layer in pretrained_IRV2.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in pretrained_Xception.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x4 = pretrained_IRV2(visible)\n",
    "x4 = tf.keras.layers.ZeroPadding2D(padding=((0, 2), (0, 2)))(x4)\n",
    "x4 = tf.keras.layers.AveragePooling2D()(x4)\n",
    "x4 = tf.keras.layers.Flatten()(x4)\n",
    "x4 = tf.keras.layers.Dense(32, activation=\"relu\")(x4)\n",
    "x4 = tf.keras.layers.Dropout(0.5)(x4)\n",
    "\n",
    "x5 = pretrained_Xception(visible)\n",
    "x5 = tf.keras.layers.AveragePooling2D()(x5)\n",
    "x5 = tf.keras.layers.Flatten()(x5)\n",
    "x5 = tf.keras.layers.Dense(32, activation=\"relu\")(x5)\n",
    "x5 = tf.keras.layers.Dropout(0.5)(x5)\n",
    "\n",
    "\n",
    "vit_model = vit.vit_b32(\n",
    "        image_size = image_size,\n",
    "        pretrained = True,\n",
    "        include_top = False,\n",
    "        pretrained_top = False)\n",
    "\n",
    "\n",
    "vit_x=vit_model(visible)\n",
    "vit_x=tf.keras.layers.Flatten()(vit_x)\n",
    "vit_x=tf.keras.layers.BatchNormalization()(vit_x)\n",
    "vit_x=tf.keras.layers.Dense(32, activation = tfa.activations.gelu)(vit_x)\n",
    "\n",
    "cnn_outputs = tf.keras.layers.concatenate([x4, x5])\n",
    "\n",
    "\n",
    "merge = tf.keras.layers.concatenate([cnn_outputs, vit_x])\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(merge)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "OUT = tf.keras.layers.Dense(33, activation='softmax')(x)\n",
    "#with tf.device('/GPU:0'):\n",
    "model = Model(inputs=visible, outputs=OUT)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PW-JFhSQePV"
   },
   "source": [
    "# train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 616
    },
    "id": "yWB9krChPifG",
    "outputId": "09cb3a9e-f754-4293-ccf6-fd06d834c3e7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 80\n",
    "learning_rate = 1e-4\n",
    "optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n",
    "print(model.summary)\n",
    "model.compile(optimizer = optimizer,\n",
    "              loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing = 0.2),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "STEP_SIZE_TRAIN = training_set.n // training_set.batch_size\n",
    "STEP_SIZE_VALID = validation_set.n // validation_set.batch_size\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                                 factor = 0.2,\n",
    "                                                 patience = 4,\n",
    "                                                 verbose = 1,\n",
    "                                                 min_delta = 1e-4,\n",
    "                                                 min_lr = 1e-6,\n",
    "                                                 mode = 'max')\n",
    "\n",
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n",
    "                                                 min_delta = 1e-4,\n",
    "                                                 patience = 10,\n",
    "                                                 mode = 'max',\n",
    "                                                 restore_best_weights = True,\n",
    "                                                 verbose = 1)\n",
    "\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(filepath = path+'.h5',\n",
    "                                                  monitor = 'val_accuracy',\n",
    "                                                  verbose = 1,\n",
    "                                                  save_best_only = True,\n",
    "\n",
    "                                                  mode = 'max')\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler,CSVLogger\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "csv_logger = CSVLogger(path+'.csv', append=True, separator=',')\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "#callbacks = [checkpoint, lr_reducer]\n",
    "\n",
    "callbacks = [earlystopping, reduce_lr, checkpointer]\n",
    "\n",
    "model.fit(x = training_set,\n",
    "          validation_data = validation_set,\n",
    "          epochs = EPOCHS,\n",
    "          callbacks = [callbacks,csv_logger])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OMoCtbFdKCxL"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow_addons as tfa\n",
    "learning_rate = 1e-4\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "optimizer = tfa.optimizers.RectifiedAdam(learning_rate = learning_rate)\n",
    "model.load_weights('models_ouput/hybrid)ensemb(InceptionResNetV2_Xception)(parallel)With_ViT.h5')\n",
    "#model.load_weights('models_ouput/hybrid)ensemb(InceptionResNetV2_Xception)(serial)With_ViT.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Df8xJJAvhD",
    "outputId": "2ae93d1c-9fcc-4a6b-9982-4653904d4c68"
   },
   "outputs": [],
   "source": [
    "#this resylt of\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred_prob = model.predict(test_set)\n",
    "\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)  # Convert probabilities to class labels\n",
    "\n",
    "# Get true labels from the test data generator\n",
    "y_true = test_set.classes\n",
    "\n",
    "# Calculate Accuracy (ACC)\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "precision = precision_score(y_true, y_pred, average='macro')  # Specify 'macro' for multiclass\n",
    "# Calculate Recall (SEN)\n",
    "recall = recall_score(y_true, y_pred, average='macro')  # Specify 'macro' for multiclass\n",
    "\n",
    "# Calculate F1-Score\n",
    "f1 = f1_score(y_true, y_pred, average='macro')  # Specify 'macro' for multiclass\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_pred_prob, multi_class='ovr', average='macro')  # Specify 'ovr' and 'macro' for multiclass\n",
    "\n",
    "# Print the results\n",
    "print(\" macro----------------------------\")\n",
    "print(f\"Accuracy (ACC): {accuracy}\")\n",
    "print(f\"Precision (PRE): {precision}\")\n",
    "print(f\"Recall (SEN): {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"AUC (Area Under ROC Curve): {roc_auc}\")\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Calculate the classification report\n",
    "#cr = classification_report(y_true, y_pred)\n",
    "\n",
    "# Calculate the F1-score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "# Calculate the accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Calculate the precision\n",
    "pre = precision_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "recall = recall_score(y_true, y_pred, average='weighted')  # Specify 'macro' for multiclass\n",
    "\n",
    "# Calculate the AUC\n",
    "auc = roc_auc_score(y_true, y_pred_prob, multi_class='ovr', average='weighted')\n",
    "\n",
    "# Calculate the sensitivity and specificity\n",
    "#fpr, tpr, thresholds = roc_curve(y_true, y_pred, pos_label=None)\n",
    "#sensitivity = tpr / (tpr + fpr)\n",
    "#specificity = 1 - sensitivity\n",
    "# Print the results\n",
    "print(\"weighted-------------------------------\")\n",
    "print(f\"Accuracy (ACC): {acc}\")\n",
    "print(f\"Precision (PRE): {pre}\")\n",
    "print(f\"Recall (SEN): {recall}\")\n",
    "print(f\"F1-Score: {f1}\")\n",
    "print(f\"AUC (Area Under ROC Curve): {auc}\")\n",
    "#print(f\"Specificity (SPE): {specificity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#hybrid)ensemb(InceptionResNetV2_Xception)(parallel)With_ViT)\n",
    "history = pd.read_csv('models_ouput/hybrid)ensemb(InceptionResNetV2_Xception)(parallel)With_ViT.csv')\n",
    "acc = history['accuracy'][:35]\n",
    "val_acc = history['val_accuracy'][:35]\n",
    "loss = history['loss'][:35]\n",
    "val_loss = history['val_loss'][:35]\n",
    "\n",
    "#plot results\n",
    "#accuracy\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "plt.rcParams['font.size'] = 14\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('epoch')\n",
    "#plt.title(f'MobileNetV2 \\nTraining and Validation Accuracy. \\nTrain Accuracy: {str(acc[-1])}\\nValidation Accuracy: {str(val_acc[-1])}')\n",
    "\n",
    "#loss\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "#plt.title(f'Training and Validation Loss. \\nTrain Loss: {str(loss[-1])}\\nValidation Loss: {str(val_loss[-1])}')\n",
    "plt.xlabel('epoch')\n",
    "plt.tight_layout(pad=3.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you already have the confusion_matrix_array and class_names\n",
    "# Define your class names\n",
    "class_names = [\n",
    "    'Eight', 'Eight Hundred', 'Eighty', 'Fifty', 'Five', 'Five Hundred',\n",
    "    'Forty', 'Four', 'Four Hundred', 'Hundred', 'Million', 'Nine',\n",
    "    'Nine Hundred', 'Ninety', 'One', 'Only', 'Reyal', 'Seven', 'Seven Hundred',\n",
    "    'Seventy', 'Six', 'Six Hundred', 'Sixty', 'Ten', 'Thirty', 'Thousand',\n",
    "    'Three', 'Three Hundred', 'Twenty', 'Two', 'Two Hundred', 'Two Million', 'Two Thousand'\n",
    "]\n",
    "\n",
    "# Replace this line with your predicted class labels\n",
    "predicted_classes = y_pred\n",
    "\n",
    "true_classes = test_set.classes\n",
    "# Create a confusion matrix\n",
    "confusion_matrix_array = confusion_matrix(true_classes, predicted_classes)\n",
    "\n",
    "# Display the confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix_array, display_labels=class_names)\n",
    "\n",
    "# Set x-axis labels rotation\n",
    "fig, ax = plt.subplots(figsize=(14, 12))\n",
    "disp.plot(cmap='Blues', values_format='d', ax=ax)\n",
    "ax.set_xticklabels(class_names, rotation=90)  # Adjust rotation angle as needed\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "classes=['Eight', 'Eight Hundred', 'Eighty', 'Fifty', 'Five', 'Five Hundred', 'Forty', 'Four', 'Four Hundred', 'Hundred', 'Million', 'Nine', 'Nine Hundred', 'Ninety', 'One', 'Only', 'Reyal', 'Seven', 'Seven Hundred', 'Seventy', 'Six', 'Six Hundred', 'Sixty', 'Ten', 'Thirty', 'Thousand', 'Three', 'Three Hundred', 'Twenty', 'Two', 'Two Hundred', 'Two Million', 'Two Thousand']\n",
    "true_labels = test_set.classes\n",
    "\n",
    "# Initialize arrays to store true labels and predicted probabilities\n",
    "true_labels_array = []\n",
    "y_pred_prob_array = []\n",
    "\n",
    "# Calculate ROC curve and AUC for each class\n",
    "num_classes = len(test_set.class_indices)\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_labels_i = (true_labels == i).astype(int)\n",
    "    y_pred_i = y_pred_prob[:, i]\n",
    "\n",
    "    fpr[i], tpr[i], _ = roc_curve(true_labels_i, y_pred_i)\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Store true labels and predicted probabilities for micro-average\n",
    "    true_labels_array.extend(true_labels_i)\n",
    "    y_pred_prob_array.extend(y_pred_i)\n",
    "\n",
    "# Calculate micro-average ROC-AUC\n",
    "micro_roc_auc = auc(fpr[0], tpr[0])\n",
    "\n",
    "# Calculate PR curve and AP for each class\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "\n",
    "for i in range(num_classes):\n",
    "    true_labels_i = (true_labels == i).astype(int)\n",
    "    y_pred_i = y_pred_prob[:, i]\n",
    "\n",
    "    precision[i], recall[i], _ = precision_recall_curve(true_labels_i, y_pred_i)\n",
    "    average_precision[i] = average_precision_score(true_labels_i, y_pred_i)\n",
    "\n",
    "# Calculate micro-average precision and recall directly\n",
    "micro_precision, micro_recall, _ = precision_recall_curve(true_labels_array, y_pred_prob_array)\n",
    "micro_average_precision = average_precision_score(true_labels_array, y_pred_prob_array)\n",
    "\n",
    "# Calculate macro-average ROC-AUC and PR\n",
    "macro_roc_auc = np.mean(list(roc_auc.values()))\n",
    "macro_average_precision = np.mean(list(average_precision.values()))\n",
    "\n",
    "# Plot ROC curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(fpr[i], tpr[i], lw=2, label=f'{classes[i]} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC)')\n",
    "plt.legend(loc='lower center',ncol=5)\n",
    "plt.show()\n",
    "\n",
    "# Plot PR curves\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(num_classes):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label=f'{classes[i]} (AP = {average_precision[i]:.2f})')\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall (PR) Curve')\n",
    "plt.legend(loc='lower center',ncol=5)\n",
    "plt.show()\n",
    "\n",
    "# Print micro and macro averages\n",
    "print(\"Micro-average ROC-AUC:\", micro_roc_auc)\n",
    "print(\"Micro-average Precision:\", micro_average_precision)\n",
    "print(\"Micro-average Recall:\", np.max(micro_recall))  # Use np.max to get the maximum recall for micro-average\n",
    "print(\"Macro-average ROC-AUC:\", macro_roc_auc)\n",
    "print(\"Macro-average Precision:\", macro_average_precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "-s9dLOVR9EJz",
    "TI1ZeAe9-NpW",
    "q4pN40l5-V3r"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
